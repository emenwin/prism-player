# Prism Player 产品需求文档（PRD）

> 版本：v0.1（草案）  
> 日期：2025-10-17  
> 适用平台：iOS（SwiftUI）、Android（Jetpack Compose），架构：MVVM  
> 非功能约束：iOS 使用 SwiftLint 严格模式；全平台不使用硬编码字符串，统一国际化（i18n）

## 1. 背景与目标

Prism Player 是一款本地音视频播放器，支持在设备本地提取媒体中的音频并进行语音转文字（ASR），将识别得到的字幕实时或准实时叠加到播放器上。目标是在完全本地（离线/低依赖网络）的前提下，提供可靠、隐私友好的字幕生成体验，帮助用户在无字幕或多语言场景下获得更好的观看与学习效率。

- 核心目标
  - 从选定的媒体中提取音频，支持预加载指定时长的音频片段以便快速开始识别。
  - 在本地调用 LLM/机器学习模型进行语音转文字，生成带时间戳的字幕。
  - 将字幕与视频播放进度同步展示，支持基础的字幕管理与导出。
- 成功指标（KPI/度量）
  - 首帧字幕可见时间（选中媒体后到首条字幕展示）：≤ 8 秒（典型中端设备，取决于模型与量化）。
  - 字幕时间同步偏差：≤ ±200ms（P95）。
  - ASR 准确率：以 WER 为准，采用轻量模型时达到业内同级水平；在端侧给出可配置模型（精度/速度权衡）。
  - 本地处理率（Realtime Factor，RTF）：≥ 0.5（即 1 分钟音频 ≤ 2 分钟处理，具体与设备有关）。

## 2. 范围（Scope）

- In Scope（首期）
  - 本地媒体选择与播放（视频/音频文件）。
  - 提取媒体音频轨（支持预加载 N 秒音频）。
  - 端侧 ASR（优先集成 Whisper.cpp 或 Vosk 之一；支持量化模型）。
  - 字幕生成（含时间戳）、渲染与同步显示。
  - 基础字幕管理：启用/关闭字幕、样式（字号/颜色/背景）、位置（底部中间为默认）。
  - 字幕导出（SRT、VTT 至少一种）。
  - 国际化与可访问性（基础）。
- Out of Scope（首期不包含）
  - 云端识别与账户系统。
  - 复杂字幕编辑器（逐词级修订、对齐校正的高级功能）。
  - 多音轨自动识别与切换（首版支持手动选择）。
  - 说话人分离（Diarization）与翻译字幕（后续评估）。

## 3. 术语

- ASR：Automatic Speech Recognition，语音转文字。
- RTF：Realtime Factor，处理时长与音频时长之比。
- 预加载（Preload）：从媒体中提前解码指定时长音频以缩短首帧字幕时间。

## 4. 用户画像与主要场景

- 学习者：观看无字幕或外语视频，快速获得基础字幕以辅助理解。
- 创作者：给素材生成草稿字幕，后续在 PC/NLE 中精修。
- 听障用户：需要本地字幕以提升观看可达性（Accessibility）。

主要场景
- 本地视频选择播放 → 立即提取前 20–60 秒音频 → 本地识别 → 播放中出现同步字幕。
- 长视频分段识别：边播边识别，滚动生成字幕。
- 完播后导出全片字幕（SRT/VTT）。

## 5. 用户故事与验收标准

1) 作为用户，我可以选择本地视频，并在数秒内看到首条字幕。
- AC1：选中媒体至首条字幕展示 ≤ 8 秒（典型设备）；失败时给出明确状态与重试。
- AC2：首条字幕时间戳与播放进度偏差 ≤ ±200ms（P95）。

2) 作为用户，我可以在播放时持续看到新的字幕滚动生成。
- AC1：正在播放的时间窗口字幕优先生成与渲染。
- AC2：字幕卡顿或缺失时，提供加载中状态或回退策略（重试/降级）。

3) 作为用户，我可以调整字幕样式与开关。
- AC1：支持字号 3 档（小/中/大）与两种主题（浅/深），默认跟随系统主题。
- AC2：切换样式不影响播放与识别进程。

4) 作为用户，我可以导出字幕文件。
- AC1：支持 SRT（首选）与 VTT 至少一种格式。
- AC2：导出包含起止时间与文本，编码为 UTF-8。

5) 作为用户，我可以在离线环境下完成识别。
- AC1：在无网络时可用；若模型未安装，提供离线安装引导（从本地文件或预置资源）。
- AC2：权限（麦克风无需；仅文件读取）请求合理、可解释。

## 6. 功能需求（FRD）

6.1 媒体选择与播放
- 支持文件选择器导入本地媒体（常见容器 MP4/MKV/MOV/MP3/AAC/WAV 等，实际解码以系统与解码库能力为准）。
- iOS：AVPlayer 播放；Android：ExoPlayer 播放。
- 播放控制：播放/暂停、拖动、跳转、倍速（0.5–2.0x）。

6.2 音频提取与预加载
- 从媒体主音轨解复用并解码为 ASR 需要的 PCM（单声道/16kHz 首选，内部可做重采样与 downmix）。
- 预加载：在选择媒体后立即提取前 N 秒（默认 30s，可配置 10–60s）的音频片段缓存，以启动首次识别。
- 后台分段：长视频按时间窗口（如 15–30s/段）滚动提取与缓存，避免一次性占用内存。

6.3 本地 ASR 引擎
- 首选方案：Whisper.cpp（int8/float16 可选，支持时间戳输出与流式增量处理）。
- 备选方案：Vosk（小模型、低资源设备友好）；iOS 可评估 Core ML 转换的 Whisper 模型；Apple Speech 的离线能力作为补充（语言与版本受限）。
- 模型管理：
  - 预置最小模型（如 tiny/ base 量化）或首次运行引导用户导入。
  - 提供模型大小/速度/准确性的提示与切换入口。
- 处理模式：
  - 优先增量/分段识别：每段 10–30s，输出带起止时间的片段文本。
  - 断点续传与错误重试，失败段可降级（更小模型或延长缓冲）。

6.4 字幕生成与同步
- 生成结果结构：list<Segment>，含 startMs、endMs、text、confidence（可选）。
- 与播放器时钟同步渲染；拖动进度时做“窗口重绘”。
- 支持多行换行与基本断句；长句按时间阈值拆分（如 4–6 秒/条）。

6.5 字幕展示与样式
- 位置：底部居中，安全区内；避免与系统手势冲突。
- 样式：字号三档、颜色（浅/深）、半透明背景。
- 开关：字幕开/关状态持久化。

6.6 字幕导出
- 至少支持 SRT；可选支持 VTT。
- 文件命名规则：<原文件名>.<locale>.srt（避免覆盖）。

6.7 设置与模型
- 模型选择与下载/导入（路径或内部资源）。
- 语言选项（auto/指定语言）；指定语言可提升速度与准确率。
- 预加载时长设置（10/30/60s）。

6.8 错误与边界处理
- 不支持的媒体：提示并引导重新选择。
- 存储空间不足：中止导出与模型下载，提示用户清理。
- 性能不足：提示可切换更小模型或降低倍速。
- 权限：文件访问被拒绝时给出可理解的引导。

## 7. 非功能需求（NFR）

- 性能：
  - 首帧字幕 ≤ 8s（典型设备+基础模型）。
  - 渲染帧率稳定（≥ 24fps 显示层面）。
- 资源占用：
  - 内存控制（ASR 段式处理，缓存上限控制）；后台任务不影响前台交互。
  - 电量：长时间识别时降低 CPU/GPU 峰值（节流、段间休眠）。
- 隐私与合规：
  - 默认全程离线，不上传任何音视频或文本。
  - 本地缓存（音频片段与字幕）可控，提供“一键清理”。
- 稳定性：
  - 崩溃率低于行业基线；失败重试与幂等。
- 国际化与可访问性：
  - 所有文案使用 i18n key；中英至少两种语言；遵循动态字体与 VoiceOver/TalkBack 可读性。
- 跨平台一致性：
  - 关键交互与结果表现一致；技术实现遵循各自平台最佳实践。

## 8. 可行性与技术选型（iOS/Android）

- 音频提取
  - iOS：AVFoundation（AVAssetReader）解复用与解码，重采样至 16kHz 单声道。
  - Android：MediaExtractor + MediaCodec 或 ExoPlayer 的音频渲染管线（自定义 AudioProcessor）。
- 本地 ASR
  - Whisper.cpp：C/C++ 实现，iOS 以静态库/Metal 加速可选；Android 以 NDK 集成，支持 int8/FP16 量化模型，提供分段/流式接口与时间戳。
  - 备选：Vosk（Kaldi/FST），模型更小，速度快，准确率相对取舍；iOS 可评估 Core ML 转换 Whisper（精度 OK，体积与加载需评估）。
- 字幕渲染
  - iOS：SwiftUI 叠加层（ZStack）+ Combine 绑定 ViewModel。
  - Android：Jetpack Compose Overlay，使用 StateFlow/LiveData 与 ViewModel 同步。
- 架构
  - MVVM：View（SwiftUI/Compose）— ViewModel（业务协调）— Repository（播放器、解码、ASR、持久化）。
  - 统一时间源：播放器进度作为渲染时钟；字幕控件消费 Segment 流。

风险与缓解
- 设备性能差异大：提供模型档位与降级策略（自动/手动）。
- 法律合规（编解码专利）：尽量使用系统解码器与合法分发的开源模型；对第三方模型以“用户自导入”为主。
- 存储体积：模型可能 >100MB；提供精简模型与按需下载。

## 9. 信息架构与数据模型

核心数据结构（示意）
- MediaSource：id、uri、durationMs、audioTrackInfo
- AudioChunk：startMs、endMs、pcmBufferRef
- TranscriptSegment：id、startMs、endMs、text、confidence?
- SubtitleTrack：segments: List<TranscriptSegment>、locale、sourceModel
- Settings：subtitleStyle、preloadSeconds、modelChoice、languageHint

持久化
- 最近媒体与最后进度（可选）。
- 模型清单与安装状态。
- 临时缓存：音频分片与中间转写结果（可清理）。

## 10. 关键交互与流程

1) 首帧字幕流程
- 选择媒体 → 解析媒体信息 → 启动预加载（30s）→ 启动 ASR（增量）→ 播放开始 → 首段字幕出现。

2) 播放中增量识别
- 循环：按窗口提取 → 送入 ASR → 产出 Segment → 合并与去重 → 渲染。

3) 导出字幕
- 汇总所有 Segment → 归并排序与相邻合并 → 生成 SRT/VTT 文本 → 保存文件。

4) 进度拖动
- 暂停渲染 → 计算新窗口 → 优先展示已识别片段 → 缺口部分标记“处理中”。

## 11. UI/UX 基线（草图要点）

- 播放页：
  - 顶部：返回、文件名；右上：设置（模型、语言、预加载时长）。
  - 中部：视频画面；字幕在底部居中，有半透明背景。
  - 底部：进度条、播放/暂停、倍速。
- 设置页：
  - 模型管理：选择/导入/查看体积与说明。
  - 语言：自动/指定。
  - 预加载：10/30/60s。
  - 字幕：字号、主题。

可访问性
- 字体随系统动态字号调整；对比度达标；屏幕阅读器读出播放器控件与状态。

## 12. 项目约束与工程规范

- iOS：SwiftUI + MVVM；SwiftLint 严格模式；不使用硬编码字符串（使用 Localizable.strings）。
- Android：Jetpack Compose + MVVM；字符串使用 resources；遵循 Kotlin lint/ktlint。
- 模块划分建议：player, extractor, asr, subtitles, settings, storage, i18n, ui。
- 日志与诊断：轻量打点与可选的本地日志导出（不含敏感媒体内容）。

## 13. 分阶段里程碑

- M1（原型，2–3 周）
  - 本地媒体播放、音频预加载、离线 ASR（最小模型）、基础字幕渲染。
- M2（可用版，3–4 周）
  - 增量识别与滚动字幕、模型管理与语言提示、SRT 导出、样式设置。
- M3（优化版，4 周）
  - 性能与能耗优化、VTT 支持、缓存清理、可访问性完善、崩溃与异常健壮性。

## 14. 验收标准（汇总）

- 功能：按第 5 章用户故事全部通过。
- 性能：首帧字幕、同步偏差、RTF 达到目标或提供明确降级路径。
- 隐私：全程离线，无外发流量（除非用户导入/下载模型）。
- 国际化：至少中英双语，禁用硬编码字符串检查通过。
- 代码质量：SwiftLint 严格模式零错误；Android 通过静态检查；单元测试覆盖关键逻辑（段合并、SRT 导出、时间同步）。

## 15. 风险与开放问题

- 不同设备的 ASR 实测性能差异需在 Beta 阶段校准目标值。
- iOS 上大型模型加载时间与内存峰值需进一步评估（可能需要懒加载与分页）。
- 版权与分发：是否预置模型？若不预置，需提供清晰的导入引导与合法合规说明。
- 语言支持范围：首期聚焦中英，其他语言在模型层面可扩展。

## 16. 指标与分析（基础）

- 离线本地埋点（不出网）：首帧时长、段处理时长、失败率、导出使用率、模型选择分布。
- 提供“问题反馈包”导出：配置、设备信息（匿名）、本地日志（脱敏）。

— 完 —
